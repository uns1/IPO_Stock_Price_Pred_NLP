{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymongo\n",
    "import json\n",
    "\n",
    "# Connect to Mongo and Get Databases\n",
    "\n",
    "mongo_connect_string = 'INSERT AMAZON STRING HERE'\n",
    "\n",
    "client = pymongo.MongoClient(mongo_connect_string)\n",
    "db = client.TwitterIPO\n",
    "RawTweets = db.RawTweets\n",
    "ProcessedTweets = db.ProcessedTweets\n",
    "PriceData = db.PriceData\n",
    "Vader = db.Vader\n",
    "MNB_Logit_SVM_Sentiment = db.MNB_Logit_SVM_Sentiment\n",
    "TweetWordCount = db.TweetWordCount\n",
    "FinalDataset = db.FinalDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get Price Date and Create a Dataframe\n",
    "prices = [x for x in PriceData.find()]\n",
    "df_prices = pd.DataFrame(prices)\n",
    "df_prices['Date'] = pd.to_datetime(df_prices.Date)\n",
    "# Format the date\n",
    "df_prices['Date'] = df_prices.Date.apply(lambda x: datetime.utcfromtimestamp(x.value / 1e9).date())\n",
    "df_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get Twitter Data\n",
    "df_tweets = pd.DataFrame(list(ProcessedTweets.find({'lang' : 'en'})))\n",
    "df_tweets.head()\n",
    "print(df_tweets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get Sentiment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_MNBLogSVM = pd.DataFrame(list(MNB_Logit_SVM_Sentiment.find()))\n",
    "df_MNBLogSVM.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Merge MNBLogSVM Data with Twitter Data\n",
    "df_senti = pd.merge(df_tweets, df_MNBLogSVM, on='UID',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_senti.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert Merged Date to Date format for joining\n",
    "df_senti.datepy = df_senti.datepy.map(lambda x: x.date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Map into Positive and Negative\n",
    "df_senti['logit_label'] = df_senti.logit_predict.map({1 : 'Positive', 0 : 'Negative'})\n",
    "df_senti['mnb_label'] = df_senti.mnb_predict.map({1 : 'Positive', 0 : 'Negative'})\n",
    "df_senti['svm_label'] = df_senti.svm_predict.map({1 : 'Positive', 0 : 'Negative'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keep columns that we want. Get rid of the rest. Divide into Seperate Tables for SVM, LOGIT & MNB for easier joining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_svm = df_senti[['company', 'datepy', 'svm_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_mnb = df_senti[['company', 'datepy', 'mnb_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_logit = df_senti[['company', 'datepy', 'logit_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get Counts of each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_counts = df_svm.groupby(by=['company','datepy'])\n",
    "svm_counts = svm_counts.svm_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnb_counts = df_mnb.groupby(by=['company','datepy'])\n",
    "mnb_counts = mnb_counts.mnb_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logit_counts = df_logit.groupby(by=['company','datepy'])\n",
    "logit_counts = logit_counts.logit_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Turn into dicts for joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm_dict = []\n",
    "for k,v in svm_counts.iteritems():\n",
    "    s = {}\n",
    "    s['Name'] = k[0]\n",
    "    s['Date'] = k[1]\n",
    "    \n",
    "    if k[2] == 'Positive':\n",
    "        s['SVM_Pos_Count'] = v\n",
    "    else:\n",
    "        s['SVM_Neg_Count'] = v\n",
    "\n",
    "    svm_dict.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnb_dict = []\n",
    "for k,v in mnb_counts.iteritems():\n",
    "    s = {}\n",
    "    s['Name'] = k[0]\n",
    "    s['Date'] = k[1]\n",
    "    \n",
    "    if k[2] == 'Positive':\n",
    "        s['MNB_Pos_Count'] = v\n",
    "    else:\n",
    "        s['MNB_Neg_Count'] = v\n",
    "\n",
    "    mnb_dict.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logit_dict = []\n",
    "for k,v in logit_counts.iteritems():\n",
    "    \n",
    "    log_res = {}\n",
    "    \n",
    "    log_res['Name'] = k[0]\n",
    "    \n",
    "    log_res['Date'] = k[1]\n",
    "    \n",
    "    if k[2] == 'Positive':\n",
    "        log_res['Logit_Pos_Count'] = v\n",
    "    else:\n",
    "        log_res['Logit_Neg_Count'] = v\n",
    "\n",
    "    logit_dict.append(log_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert back to dataframes and reset index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_counts = pd.DataFrame(svm_dict)\n",
    "svm_counts = svm_counts.groupby(['Name','Date']).sum()\n",
    "svm_counts = svm_counts.fillna(0)\n",
    "svm_counts = svm_counts.reset_index(level=['Date','Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnb_counts = pd.DataFrame(mnb_dict)\n",
    "mnb_counts = mnb_counts.groupby(['Name','Date']).sum()\n",
    "mnb_counts = mnb_counts.fillna(0)\n",
    "mnb_counts = mnb_counts.reset_index(level=['Date','Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logit_counts = pd.DataFrame(logit_dict)\n",
    "logit_counts = logit_counts.groupby(['Name','Date']).sum()\n",
    "logit_counts = logit_counts.fillna(0)\n",
    "logit_counts = logit_counts.reset_index(level=['Date','Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> TweetWordCount - Average Ratio & Counts </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get Tweet Word Count and merge with Processed Tweets\n",
    "df_tweetwordcount = pd.DataFrame(list(TweetWordCount.find()))\n",
    "df_tweetwordcount = pd.merge(df_tweets, df_tweetwordcount, on='UID',how='inner')\n",
    "\n",
    "# Convert Datetime object to date\n",
    "df_tweetwordcount.datepy = df_tweetwordcount.datepy.map(lambda x: x.date())\n",
    "\n",
    "# Add Labels\n",
    "df_tweetwordcount['twc_label'] = np.where(df_tweetwordcount['ratio'] > 0, 'Positive','Negative')\n",
    "df_tweetwordcount.loc[df_tweetwordcount.ratio == 0, 'twc_label'] = 'Neutral'\n",
    "\n",
    "# Groupby Date and Company for Average Ratio\n",
    "df_tweetwordcount_ratio = df_tweetwordcount.groupby(['datepy','company']).mean()\n",
    "\n",
    "# Keep Date, Company & Ratio\n",
    "df_tweetwordcount_ratio = df_tweetwordcount_ratio[['ratio']]\n",
    "df_tweetwordcount_ratio = df_tweetwordcount_ratio.reset_index(['datepy','company'])\n",
    "df_tweetwordcount_ratio = df_tweetwordcount_ratio.rename(columns={'datepy' : 'Date','company':'Name','ratio' : 'WordCountRatio'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get Counts\n",
    "\n",
    "df_tweetwordcount_counts = df_tweetwordcount[['company', 'datepy', 'twc_label']]\n",
    "\n",
    "twc_counts = df_tweetwordcount_counts.groupby(by=['company','datepy'])\n",
    "twc_counts = twc_counts.twc_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "twc_dict = []\n",
    "for k,v in twc_counts.iteritems():\n",
    "    s = {}\n",
    "    s['Name'] = k[0]\n",
    "    s['Date'] = k[1]\n",
    "    \n",
    "    if k[2] == 'Positive':\n",
    "        s['TWC_Pos_Count'] = v\n",
    "    elif k[2] == 'Neutral':\n",
    "        s['TWC_Neutral_Count'] = v\n",
    "    else:\n",
    "        s['TWC_Neg_Count'] = v\n",
    "\n",
    "    twc_dict.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "twc_counts = pd.DataFrame(twc_dict)\n",
    "twc_counts = twc_counts.groupby(['Name','Date']).sum()\n",
    "twc_counts = twc_counts.fillna(0)\n",
    "twc_counts = twc_counts.reset_index(level=['Date','Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Vader Incorporation </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saifi\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Get Tweet Word Count and merge with Processed Tweets\n",
    "df_vader = pd.DataFrame(list(Vader.find()))\n",
    "df_vader = pd.merge(df_tweets, df_vader, on='UID',how='inner')\n",
    "\n",
    "# Convert Datetime object to date\n",
    "df_vader.datepy = df_vader.datepy.map(lambda x: x.date())\n",
    "\n",
    "# Add Labels\n",
    "df_vader['vader_label'] = np.where(df_vader['compound'] > 0, 'Positive','Negative')\n",
    "criterion = df_vader['compound'].map(lambda x: x == 0)\n",
    "df_vader['vader_label'][criterion] = 'Neutral'\n",
    "\n",
    "# Groupby Date and Company for Average compound\n",
    "df_vader_score = df_vader.groupby(['datepy','company']).mean()\n",
    "\n",
    "# Keep Date, Company & compound\n",
    "df_vader_score = df_vader_score[['compound','neg','neu','pos']]\n",
    "df_vader_score = df_vader_score.reset_index(['datepy','company'])\n",
    "df_vader_score = df_vader_score.rename(columns={'datepy' : 'Date',\n",
    "                                                'company':'Name',\n",
    "                                                'compound' : 'Vader_Compound',\n",
    "                                                'neg' : 'Vader_Neg',\n",
    "                                                'neu': 'Vader_Neu',\n",
    "                                                'pos' : 'Vader_Pos'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Get Vader Label Counts\n",
    "\n",
    "df_vader_counts = df_vader[['company', 'datepy', 'vader_label']]\n",
    "\n",
    "vader_counts = df_vader_counts.groupby(by=['company','datepy'])\n",
    "vader_counts = vader_counts.vader_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vader_dict = []\n",
    "for k,v in vader_counts.iteritems():\n",
    "    \n",
    "    s = {}\n",
    "    s['Name'] = k[0]\n",
    "    s['Date'] = k[1]\n",
    "    \n",
    "    if k[2] == 'Positive':\n",
    "        s['Vader_Pos_Count'] = v\n",
    "    elif k[2] == 'Neutral':\n",
    "        s['Vader_Neutral_Count'] = v\n",
    "    else:\n",
    "        s['Vader_Neg_Count'] = v\n",
    "\n",
    "    vader_dict.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vader_counts = pd.DataFrame(vader_dict)\n",
    "vader_counts = vader_counts.groupby(['Name','Date']).sum()\n",
    "vader_counts = vader_counts.fillna(0)\n",
    "vader_counts = vader_counts.reset_index(level=['Date','Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Merge all Sentiment Datasets</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Merge Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_senti_combined = pd.merge(svm_counts, mnb_counts, on=['Date','Name'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_senti_combined = pd.merge(df_senti_combined,logit_counts, on=['Date','Name'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_senti_combined = pd.merge(df_senti_combined,twc_counts, on=['Date','Name'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_senti_combined = pd.merge(df_senti_combined,vader_counts, on=['Date','Name'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Merge Scores, Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_senti_combined = pd.merge(df_senti_combined,df_tweetwordcount_ratio, on=['Date','Name'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_senti_combined = pd.merge(df_senti_combined,df_vader_score, on=['Date','Name'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Shift date by +1 to merge with price data of next day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_senti_combined['Date'] = df_senti_combined.Date.map(lambda x: x + timedelta(days=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Combine Sentiment and Price </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_combined = pd.merge(df_prices,df_senti_combined, on=['Date','Name'], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_combined = df_combined.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(807, 36)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Write to CSV for testing in WEKA?\n",
    "# df_combined.to_csv('test_senti.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Insert into MongoDB (Needs Date converstion to Datetime)\n",
    "df_combined.Date = df_combined.Date.map(lambda t: datetime(t.year, t.month, t.day))\n",
    "FinalDataset.insert_many(df_combined.to_dict('records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
